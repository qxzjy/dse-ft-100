{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing temlate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 - Import librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Since the Scikit library is big, we only import what we need\n",
    "\n",
    "# train_test_split : method to split the dataset (DataFrame) into two distinct : one for training, one for testing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# SimpleImputer : class which allow us to fill missing values (null, NaN) with specific strategy (median, mean, mode, etc.)\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# StandardScaler : class which allow us to standardize (put on the same scale) numerical features (using z-score)\n",
    "# OneHotEncoder : class which allow us to encode categorical features (create a column per category that contain only 0 and 1)\n",
    "# LabelEncoder : class which allow us to encode labels (same as categorical, but with a \"binary\" template of data) \n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "\n",
    "# ColumnTransformer : : class which allow us to use scalers and encoders ojects to transform our DataFrames, returning numpy arrays\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 - Import dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Age</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Purchased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>France</td>\n",
       "      <td>44.0</td>\n",
       "      <td>72000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Spain</td>\n",
       "      <td>27.0</td>\n",
       "      <td>48000.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Germany</td>\n",
       "      <td>30.0</td>\n",
       "      <td>54000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Spain</td>\n",
       "      <td>38.0</td>\n",
       "      <td>61000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Germany</td>\n",
       "      <td>40.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Country   Age   Salary Purchased\n",
       "0   France  44.0  72000.0        No\n",
       "1    Spain  27.0  48000.0       Yes\n",
       "2  Germany  30.0  54000.0        No\n",
       "3    Spain  38.0  61000.0        No\n",
       "4  Germany  40.0      NaN       Yes"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"/Users/qxzjy/vscworkspace/dse-ft-100/ml_module/data/Data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows , Columuns : (10, 4)\n",
      "\n",
      "       Country        Age        Salary Purchased\n",
      "count       10   9.000000      9.000000        10\n",
      "unique       3        NaN           NaN         2\n",
      "top     France        NaN           NaN        No\n",
      "freq         4        NaN           NaN         5\n",
      "mean       NaN  38.777778  63777.777778       NaN\n",
      "std        NaN   7.693793  12265.579662       NaN\n",
      "min        NaN  27.000000  48000.000000       NaN\n",
      "25%        NaN  35.000000  54000.000000       NaN\n",
      "50%        NaN  38.000000  61000.000000       NaN\n",
      "75%        NaN  44.000000  72000.000000       NaN\n",
      "max        NaN  50.000000  83000.000000       NaN\n"
     ]
    }
   ],
   "source": [
    "# Print the shape of dataset in the form of (#rows, #columns)\n",
    "print(f\"Rows , Columuns : {df.shape}\")\n",
    "print()\n",
    "\n",
    "# Describe dataset's main statistics\n",
    "# We're using the include=\"all\" attribut because we want to see/explore all values (not only numbers)\n",
    "# We need to see if there's missing values (null / NaN) and the type of data we have (numerical, categorical, labels, etc.)\n",
    "print(df.describe(include=\"all\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 - Separate Target from feature variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Separating labels from features...\n",
      "...Done.\n",
      "\n",
      "   Country   Age   Salary\n",
      "0   France  44.0  72000.0\n",
      "1    Spain  27.0  48000.0\n",
      "2  Germany  30.0  54000.0\n",
      "3    Spain  38.0  61000.0\n",
      "4  Germany  40.0      NaN\n",
      "\n",
      "0     No\n",
      "1    Yes\n",
      "2     No\n",
      "3     No\n",
      "4    Yes\n",
      "Name: Purchased, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(\"Separating labels from features...\")\n",
    "\n",
    "# We create two separate DataFrames, one with our features X and one for the target variable Y (that we want to predict)\n",
    "# We're using a List to enumerate the columns that we're going to use as features X\n",
    "features_list = [\"Country\", \"Age\", \"Salary\"]\n",
    "X = df.loc[:,features_list]\n",
    "y = df.loc[:,\"Purchased\"]\n",
    "\n",
    "print(\"...Done.\")\n",
    "print()\n",
    "\n",
    "print(X.head())\n",
    "print()\n",
    "print(y.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4 - Train / Test split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting dataset into train set and test set...\n",
      "...Done.\n",
      "\n",
      "   Country   Age   Salary\n",
      "4  Germany  40.0      NaN\n",
      "9   France  37.0  67000.0\n",
      "1    Spain  27.0  48000.0\n",
      "6    Spain   NaN  52000.0\n",
      "7   France  48.0  79000.0\n",
      "3    Spain  38.0  61000.0\n",
      "0   France  44.0  72000.0\n",
      "5   France  35.0  58000.0\n",
      "\n",
      "4    Yes\n",
      "9    Yes\n",
      "1    Yes\n",
      "6     No\n",
      "7    Yes\n",
      "3     No\n",
      "0     No\n",
      "5    Yes\n",
      "Name: Purchased, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(\"Splitting dataset into train set and test set...\")\n",
    "\n",
    "# The method will return 4 arrays : 2 with features X and 2 with target variables y (each time : 1 for training the model, 1 for testing it)\n",
    "# X : our DataFrames of features\n",
    "# y : our DataFrames of target variables\n",
    "# test_size : the size of the training set compared with total set, using proportion => 0.20 (20%)\n",
    "# random_state : the method we use to randomly selected our data\n",
    "# stratify : allows to stratify your sample (same proportion of categories in test and train set) on a specific column\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "print(\"...Done.\")  \n",
    "print()                    \n",
    "\n",
    "print(X_train)\n",
    "print()                    \n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5 - Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Training pipeline ---\n"
     ]
    }
   ],
   "source": [
    "print(\"--- Training pipeline ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputing missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputing missing values...\n",
      "\n",
      "   Country   Age   Salary\n",
      "4  Germany  40.0      NaN\n",
      "9   France  37.0  67000.0\n",
      "1    Spain  27.0  48000.0\n",
      "6    Spain   NaN  52000.0\n",
      "7   France  48.0  79000.0\n",
      "3    Spain  38.0  61000.0\n",
      "0   France  44.0  72000.0\n",
      "5   France  35.0  58000.0\n",
      "\n",
      "...Done!\n",
      "\n",
      "   Country        Age        Salary\n",
      "4  Germany  40.000000  62428.571429\n",
      "9   France  37.000000  67000.000000\n",
      "1    Spain  27.000000  48000.000000\n",
      "6    Spain  38.428571  52000.000000\n",
      "7   France  48.000000  79000.000000\n",
      "3    Spain  38.000000  61000.000000\n",
      "0   France  44.000000  72000.000000\n",
      "5   France  35.000000  58000.000000\n"
     ]
    }
   ],
   "source": [
    "print(\"Imputing missing values...\")\n",
    "print()\n",
    "\n",
    "# Instanciate class of SimpleImputer with strategy of mean\n",
    "imputer = SimpleImputer(strategy=\"mean\")\n",
    "\n",
    "# Copy dataset to avoid caveats of assign a copy of a slice of a DataFrame\n",
    "X_train = X_train.copy()\n",
    "print(X_train)\n",
    "print()\n",
    "\n",
    "# Fit and transform columns where there are missing values\n",
    "# Alternative : X_train.loc[:,[\"Age\", \"Salary\"]] = imputer.fit_transform(X_train.iloc[:,[\"Age\", \"Salary\"]])\n",
    "X_train.iloc[:,[1,2]] = imputer.fit_transform(X_train.iloc[:,[1,2]])\n",
    "\n",
    "print(\"...Done!\")\n",
    "print()\n",
    "\n",
    "print(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardizing (scaling) and encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding categorical features and standardizing numerical features...\n",
      "\n",
      "...Done.\n",
      "\n",
      "[[ 0.          1.          0.          0.27063731  0.        ]\n",
      " [ 1.          0.          0.         -0.24603392  0.47997   ]\n",
      " [ 0.          0.          1.         -1.96827133 -1.51490532]\n",
      " [ 0.          0.          1.          0.         -1.09493157]\n",
      " [ 1.          0.          0.          1.64842723  1.73989126]]\n",
      "\n",
      "Encoding labels...\n",
      "4    Yes\n",
      "9    Yes\n",
      "1    Yes\n",
      "6     No\n",
      "7    Yes\n",
      "3     No\n",
      "0     No\n",
      "5    Yes\n",
      "Name: Purchased, dtype: object\n",
      "\n",
      "...Done.\n",
      "\n",
      "[1 1 1 0 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Encoding categorical features and standardizing numerical features...\")\n",
    "print()\n",
    "\n",
    "# We create a list with ids of columns containing numerical features in order to standardize them \n",
    "numeric_features = [1, 2]\n",
    "numeric_transformer = StandardScaler()\n",
    "\n",
    "# We create a list with ids of columns containing categorical features in order to encode them \n",
    "categorical_features = [0]\n",
    "categorical_transformer = OneHotEncoder(drop=\"first\")\n",
    "\n",
    "# Instansiate the class ColumnTransformer with our transformers (in this case : one for scaling, one for encoding)\n",
    "featureencoder = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', categorical_transformer, categorical_features),    \n",
    "        ('num', numeric_transformer, numeric_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "X_train = featureencoder.fit_transform(X_train)\n",
    "print(\"...Done.\")\n",
    "print()\n",
    "print(X_train[:5]) # print first 5 rows (not using iloc since now X_train became a numpy array)\n",
    "print()\n",
    "\n",
    "# Encoding labels\n",
    "print(\"Encoding labels...\")\n",
    "print(y_train)\n",
    "print()\n",
    "\n",
    "labelencoder = LabelEncoder()\n",
    "Y_train = labelencoder.fit_transform(y_train)\n",
    "\n",
    "print(\"...Done.\")\n",
    "print()\n",
    "print(Y_train[:5]) # print first 5 rows (not using iloc since now y_train became a numpy array)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** HERE WILL BE THE TRAINING STEP (NOT IN THE SCOPE AT THIS STAGE OF THE LECTURE) ***\n"
     ]
    }
   ],
   "source": [
    "print(\"*** HERE WILL BE THE TRAINING STEP (NOT IN THE SCOPE AT THIS STAGE OF THE LECTURE) ***\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6 - Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Test pipeline ---\n",
      "Imputing missing values...\n",
      "\n",
      "   Country   Age   Salary\n",
      "2  Germany  30.0  54000.0\n",
      "8  Germany  50.0  83000.0\n",
      "\n",
      "...Done.\n",
      "\n",
      "   Country   Age   Salary\n",
      "2  Germany  30.0  54000.0\n",
      "8  Germany  50.0  83000.0\n",
      "\n",
      "Encoding categorical features and standardizing numerical features...\n",
      "\n",
      "...Done.\n",
      "\n",
      "[[ 0.          1.          0.         -1.4516001  -0.88494469]\n",
      " [ 0.          1.          0.          1.99287472  2.15986501]]\n",
      "\n",
      "Encoding labels...\n",
      "\n",
      "2    No\n",
      "8    No\n",
      "Name: Purchased, dtype: object\n",
      "\n",
      "...Done.\n",
      "\n",
      "[0 0]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"--- Test pipeline ---\")\n",
    "\n",
    "# Missing values\n",
    "print(\"Imputing missing values...\")\n",
    "print()\n",
    "print(X_test)\n",
    "print()\n",
    "# Copy dataset to avoid caveats of assign a copy of a slice of a DataFrame\n",
    "X_test = X_test.copy()\n",
    "\n",
    "# /!\\ We don't use the fit_transform on test sets /!\\\n",
    "X_test.iloc[:,[1,2]] = imputer.transform(X_test.iloc[:,[1,2]])\n",
    "print(\"...Done.\")\n",
    "print()\n",
    "print(X_test) \n",
    "print()   \n",
    "\n",
    "# Encoding categorical features and standardizing numeric features\n",
    "print(\"Encoding categorical features and standardizing numerical features...\")\n",
    "print()\n",
    "\n",
    "# /!\\ We don't use the fit_transform on test sets /!\\\n",
    "X_test = featureencoder.transform(X_test)\n",
    "print(\"...Done.\")\n",
    "print()\n",
    "print(X_test)\n",
    "print()\n",
    "\n",
    "# Encoding labels\n",
    "print(\"Encoding labels...\")\n",
    "print()\n",
    "print(y_test)\n",
    "print()\n",
    "\n",
    "# /!\\ We don't use the fit_transform on test sets /!\\\n",
    "y_test = labelencoder.transform(y_test)\n",
    "print(\"...Done.\")\n",
    "print()\n",
    "print(y_test)\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7 - Predict and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** HERE WILL BE THE PREDICTION STEP ***\n",
      "\n",
      "*** HERE WILL BE THE ASSESSMENT OF PERFORMANCES ***\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"*** HERE WILL BE THE PREDICTION STEP ***\")\n",
    "print()\n",
    "print(\"*** HERE WILL BE THE ASSESSMENT OF PERFORMANCES ***\")\n",
    "print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
